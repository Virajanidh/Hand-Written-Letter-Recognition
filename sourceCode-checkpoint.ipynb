{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd63ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a13f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data...\n",
    "data = pd.read_csv(r\"D:\\semester6\\CO542NeuralNetworksandFuzzySystems\\project\\archive\\A_Z Handwritten Data.csv\").astype('float32')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data the X - Our data , and y - the prdict label\n",
    "X = data.drop('0',axis = 1)\n",
    "y = data['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training & testing dataset\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Reshaping the data in csv file so that it can be displayed as an image\n",
    "# initially in the CSV file they were present as 784 columns of pixel data. So convert it to 28Ã—28 pixels.\n",
    "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
    "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
    "\n",
    "print(\"Train data shape: \", train_x.shape)\n",
    "print(\"Test data shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for getting characters from index values\n",
    "\n",
    "#All the labels are present in the form of floating point values, that after convert to integer values\n",
    "#So here map those integer values with Alphebet\n",
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75393f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the number of alphabets in the dataset\n",
    "\n",
    "#convert labels into integer values\n",
    "train_yint = np.int0(y)\n",
    "count = np.zeros(26, dtype='int')\n",
    "\n",
    "#count number of charactors for each charactor\n",
    "for i in train_yint:\n",
    "    count[i] +=1\n",
    "\n",
    "#store A to Z in alphabets list using values of word_dict\n",
    "alphabets = []\n",
    "for i in word_dict.values():\n",
    "    alphabets.append(i)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.barh(alphabets, count)\n",
    "\n",
    "plt.xlabel(\"Number of elements \")\n",
    "plt.ylabel(\"Alphabets\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data in order to display some random images.\n",
    "shuff = shuffle(train_x[:100])\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
    "axes = ax.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50334fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the training & test dataset so that it can be put in the model \n",
    "\n",
    "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "print(\"New shape of train data: \", train_X.shape)\n",
    "\n",
    "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
    "print(\"New shape of test data: \", test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa188a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to categorical values...\n",
    "\n",
    "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of train labels: \", train_yOHE.shape)\n",
    "\n",
    "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of test labels: \", test_yOHE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b1e71d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23536/2194145654.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_yOHE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_yOHE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "\n",
    "model.add(Dense(26,activation =\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "history = model.fit(train_X, train_yOHE, epochs=4, callbacks=[reduce_lr, early_stop],  validation_data = (test_X,test_yOHE))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.save(r'model_hand.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the accuracies & losses for train & validation set\n",
    "\n",
    "print(\"The validation accuracy is :\", history.history['val_accuracy'])\n",
    "print(\"The training accuracy is :\", history.history['accuracy'])\n",
    "print(\"The validation loss is :\", history.history['val_loss'])\n",
    "print(\"The training loss is :\", history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\"],loc=\"upper left\")\n",
    "plt.savefig(\"acc_avg_pool_relu_t.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"validation\"],loc=\"upper left\")\n",
    "plt.savefig(\"acc_avgpool_relu_v.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\"],loc=\"upper left\")\n",
    "plt.savefig(\"loss_avgpool_relu_t.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737becac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel('validation loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"validation\"],loc=\"upper left\")\n",
    "plt.savefig(\"loss_avgpool_relu_v.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f5a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18579c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making model predictions\n",
    "\n",
    "pred = model.predict(test_X[:9])\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying some of the test images & their predicted labels...\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    img = np.reshape(test_X[i], (28,28))\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    pred = word_dict[np.argmax(test_yOHE[i])]\n",
    "    ax.set_title(\"Prediction: \"+pred)\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on external image...\n",
    "\n",
    "img = cv2.imread(r'D:\\semester6\\CO542NeuralNetworksandFuzzySystems\\project\\let_B.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (400,440))\n",
    "\n",
    "img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "img_final = cv2.resize(img_thresh, (28,28))\n",
    "img_final =np.reshape(img_final, (1,28,28,1))\n",
    "\n",
    "\n",
    "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
    "\n",
    "cv2.putText(img, \"Entered letter \", (20,25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color = (0,0,230))\n",
    "cv2.putText(img, \"Prediction: \" + img_pred, (20,410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))\n",
    "cv2.imshow('handwritten character recognition : ', img)\n",
    "\n",
    "\n",
    "while (1):\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baff4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc799850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243019b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
